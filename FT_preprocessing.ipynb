{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file is meant to preprocess the mgf data for contrastive fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dreams.utils.data import MSData, evaluate_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dreams.api import dreams_embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import umap\n",
    "from dreams.utils.mols import formula_type\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from dreams.utils.plots import init_plotting\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = MSData.from_mgf('data/mgf_MoNA_experimental.mgf', in_mem=False)\n",
    "print(data_full)\n",
    "print(data_full.columns())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get meaningful subset of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = 10000\n",
    "SAMPLE_DATASET = f\"data/MoNA_experimental_{total_samples}.hdf5\"\n",
    "\n",
    "spectrum_types = data_full['SPECTRUM_TYPE']\n",
    "spectrum_types = np.array(spectrum_types)\n",
    "unique_types, type_counts = np.unique(spectrum_types, return_counts=True)\n",
    "\n",
    "print(\"Spectrum Types and their counts:\")\n",
    "for type, count in zip(unique_types, type_counts):\n",
    "    print(f\"{type}: {count}\")\n",
    "\n",
    "\n",
    "type_proportions = type_counts / len(spectrum_types)\n",
    "\n",
    "samples_per_type = np.round(type_proportions * total_samples).astype(int)\n",
    "\n",
    "sampled_indices = []\n",
    "\n",
    "for spectrum_type, n_samples in zip(unique_types, samples_per_type):\n",
    "    type_indices = np.where(spectrum_types == spectrum_type)[0]\n",
    "    \n",
    "    # If we have fewer spectra of this type than we want to sample, take all of them\n",
    "    if len(type_indices) <= n_samples:\n",
    "        sampled_indices.extend(type_indices)\n",
    "    else:\n",
    "        sampled_indices.extend(np.random.choice(type_indices, size=n_samples, replace=False))\n",
    "\n",
    "\n",
    "# Ensure we have exactly total_samples samples\n",
    "sampled_indices = sampled_indices[:total_samples]\n",
    "sampled_spectra = data_full.get_spectra()[sampled_indices]\n",
    "print(f\"Total sampled indices: {len(sampled_indices)}\")\n",
    "print(\"Print 3 random samples (sanity check):\")\n",
    "print_indices = np.random.choice(sampled_indices, size=3, replace=False)\n",
    "for i in print_indices:\n",
    "    print(data_full.at(i))\n",
    "\n",
    "data_short = data_full.form_subset(sampled_indices, SAMPLE_DATASET)\n",
    "del data_short\n",
    "data_short = MSData(SAMPLE_DATASET, mode='a')\n",
    "data_short.add_column(\"ORIGINAL_INDEX\", sampled_indices)\n",
    "print(\"\\nSampled dataset saved!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create constrastive dataset according to paper and ContrastiveSpectraDataset class in data.py line 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_short_pd = data_short.to_pandas()\n",
    "data_short_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_23760\\2877952091.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  contrastive_df['INCHI_PREFIX'] = contrastive_df['INCHIKEY'].str[:14]\n",
      "100%|██████████| 2000/2000 [00:03<00:00, 550.42it/s] \n"
     ]
    }
   ],
   "source": [
    "# reduced parameters from paper due to computational constraints\n",
    "n_spectra=8000\n",
    "n_unique_inchi=2000 \n",
    "mass_diff=0.05\n",
    "\n",
    "# Apply filters: [M+H]+ adducts and 60 eV collision energy\n",
    "# how to filter by collision energy?\n",
    "contrastive_df = data_short_pd[data_short_pd['charge'] == '[M+H]+']\n",
    "\n",
    "# Group by first 14 characters of InChIKey\n",
    "contrastive_df['INCHI_PREFIX'] = contrastive_df['INCHIKEY'].str[:14]\n",
    "grouped = contrastive_df.groupby('INCHI_PREFIX')\n",
    "\n",
    "\n",
    "# Sample InChI groups\n",
    "sampled_groups = grouped.size().nlargest(n_unique_inchi).index\n",
    "\n",
    "# Create dataset\n",
    "dataset = []\n",
    "for inchi in tqdm(sampled_groups):\n",
    "    group = grouped.get_group(inchi)\n",
    "    \n",
    "    # Sample spectra from this group\n",
    "    n_samples = min(len(group), max(1, int(n_spectra / len(sampled_groups))))\n",
    "    sampled_spectra = group.sample(n=n_samples)\n",
    "    \n",
    "    for idx, ref in sampled_spectra.iterrows():\n",
    "        # Positive examples: same InChI, different spectrum\n",
    "        pos_candidates = group[group.index != idx]\n",
    "        pos_idx = pos_candidates.index.tolist()\n",
    "        \n",
    "        # Negative examples: different InChI, similar mass\n",
    "        neg_candidates = contrastive_df[\n",
    "            (contrastive_df['INCHI_PREFIX'] != ref['INCHI_PREFIX']) & \n",
    "            (abs(contrastive_df['EXACTMASS'] - ref['EXACTMASS']) <= mass_diff)\n",
    "        ]\n",
    "        neg_idx = neg_candidates.index.tolist()\n",
    "        \n",
    "        if len(pos_idx) > 0 and len(neg_idx) > 0:\n",
    "                entry = {\n",
    "                    'index': idx,\n",
    "                    'pos_idx': pos_idx,\n",
    "                    'neg_idx': neg_idx,\n",
    "                    'INCHI_PREFIX': inchi,\n",
    "                    'PRECURSOR M/Z':ref['precursor_mz'],\n",
    "                    'PARSED PEAKS': ref[\"spectrum\"],\n",
    "                    'CHARGE': ref['charge'],\n",
    "                    'ROMol': Chem.MolFromSmiles(ref['smiles'])\n",
    "                }\n",
    "                # Add all original columns\n",
    "                for col in contrastive_df.columns:\n",
    "                    entry[col] = ref[col]\n",
    "                dataset.append(entry)\n",
    "\n",
    "# Create a new DataFrame from the dataset\n",
    "contrastive_df = pd.DataFrame(dataset)\n",
    "\n",
    "import dreams.utils.spectra as su \n",
    "contrastive_df = su.df_to_MSnSpectra(contrastive_df, as_new_column=True, assert_is_valid=False)\n",
    "\n",
    "# Ensure we have the desired number of spectra\n",
    "if len(contrastive_df) > n_spectra:\n",
    "    contrastive_df = contrastive_df.sample(n=n_spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dreams.utils.spectra as su \n",
    "# add MSnSpectra as new column\n",
    "contrastive_df['PRECURSOR M/Z'] = contrastive_df['precursor_mz']\n",
    "contrastive_df['PARSED PEAKS'] = contrastive_df[\"spectrum\"]\n",
    "contrastive_df['CHARGE'] = contrastive_df['charge']\n",
    "contrastive_df = su.df_to_MSnSpectra(contrastive_df, as_new_column=True, assert_is_valid=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Murcko histogram split according to https://github.com/pluskal-lab/DreaMS/blob/main/tutorials/murcko_hist_split.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1088/1088 [00:00<00:00, 1757.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num. unique smiles: 1088 Num. unique Murcko histograms: 52\n",
      "Top 20 most common Murcko histograms:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from dreams.algorithms.murcko_hist import murcko_hist\n",
    "# some smiles are invalid?\n",
    "def is_valid_smiles(smiles):\n",
    "    if pd.isna(smiles) or smiles == 'n/a':\n",
    "        return False\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return mol is not None\n",
    "\n",
    "\n",
    "# Compute Murcko histograms\n",
    "\n",
    "contrastive_df = contrastive_df[contrastive_df['smiles'].apply(is_valid_smiles)]\n",
    "df_us = contrastive_df.drop_duplicates(subset=['smiles']).copy()\n",
    "\n",
    "df_us['MurckoHist'] = df_us['smiles'].progress_apply(\n",
    "    lambda x: murcko_hist.murcko_hist(Chem.MolFromSmiles(x))\n",
    ")\n",
    "\n",
    "# Convert dictionaries to strings for easier handling\n",
    "df_us['MurckoHistStr'] = df_us['MurckoHist'].astype(str)\n",
    "print('Num. unique smiles:', df_us['smiles'].nunique(), 'Num. unique Murcko histograms:', df_us['MurckoHistStr'].nunique())\n",
    "print('Top 20 most common Murcko histograms:')\n",
    "df_us['MurckoHistStr'].value_counts()[:20]\n",
    "\n",
    "# Group by MurckoHistStr and aggregate\n",
    "df_gb = df_us.groupby('MurckoHistStr').agg(\n",
    "    count=('smiles', 'count'),\n",
    "    smiles_list=('smiles', list)\n",
    ").reset_index()\n",
    "\n",
    "# Convert MurckoHistStr to MurckoHist\n",
    "df_gb['MurckoHist'] = df_gb['MurckoHistStr'].apply(eval)\n",
    "\n",
    "# Sort by 'n' in descending order and reset index\n",
    "df_gb = df_gb.sort_values('count', ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of spectra:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold\n",
       "train    0.75724\n",
       "val      0.24276\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of smiles:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fold\n",
       "train    0.756434\n",
       "val      0.243566\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split the dataset into training and validation sets based on Murcko histograms\n",
    "\n",
    "median_i = len(df_gb) // 2\n",
    "cum_val_mols = 0\n",
    "val_mols_frac = 0.15  # Approximately 15% of the molecules go to validation set\n",
    "val_idx, train_idx = [], []\n",
    "\n",
    "# Iterate from median to start, assigning molecules to train or val sets\n",
    "for i in range(median_i, -1, -1):\n",
    "    current_hist = df_gb.iloc[i]['MurckoHist']\n",
    "    is_val_subhist = any(\n",
    "        murcko_hist.are_sub_hists(current_hist, df_gb.iloc[j]['MurckoHist'], k=3, d=4)\n",
    "        for j in val_idx\n",
    "    )\n",
    "\n",
    "    if is_val_subhist:\n",
    "        train_idx.append(i)\n",
    "    else:\n",
    "        if cum_val_mols / len(df_us) <= val_mols_frac:\n",
    "            cum_val_mols += df_gb.iloc[i]['count']\n",
    "            val_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "\n",
    "# Add remaining indices to train set\n",
    "train_idx.extend(range(median_i + 1, len(df_gb)))\n",
    "assert(len(train_idx) + len(val_idx) == len(df_gb))\n",
    "\n",
    "# Map SMILES to their assigned fold\n",
    "smiles_to_fold = {}\n",
    "for i, row in df_gb.iterrows():\n",
    "    fold = 'val' if i in val_idx else 'train'\n",
    "    for smiles in row['smiles_list']:\n",
    "        smiles_to_fold[smiles] = fold\n",
    "contrastive_df['fold'] = contrastive_df['smiles'].map(smiles_to_fold)\n",
    "\n",
    "# Display fold distributions\n",
    "print('Distribution of spectra:')\n",
    "display(contrastive_df['fold'].value_counts(normalize=True))\n",
    "print('Distribution of smiles:')\n",
    "display(contrastive_df.drop_duplicates(subset=['smiles'])['fold'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate data leakage\n",
    "eval_res = evaluate_split(contrastive_df, n_workers=4)\n",
    "init_plotting(figsize=(3, 3))\n",
    "sns.histplot(eval_res['val'], bins=100)\n",
    "plt.xlabel('Max Tanimoto similarity to training set')\n",
    "plt.ylabel('Num. validation set molecules')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataset to pickle (required by train.py)\n",
    "contrastive_df.to_pickle(f'data/MoNA_experimental_split_{n_spectra}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrastive fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreams",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
